{
  "paragraphs": [
    {
      "text": "%md\n## Exploration des donnees GDELT via Spark\nDans ce notebook nous allons commencer a explorer les donnees GDELT qu\u0027on a stoque sur S3",
      "user": "anonymous",
      "dateUpdated": "2019-01-07 22:31:37.233",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eExploration des donnees GDELT via Spark\u003c/h2\u003e\n\u003cp\u003eDans ce notebook nous allons commencer a explorer les donnees GDELT qu\u0026rsquo;on a stoque sur S3\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546896697228_1923790317",
      "id": "20181212-102323_67420128",
      "dateCreated": "2019-01-07 22:31:37.228",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "sc.hadoopConfiguration.set(\"fs.s3a.access.key\", \"TODO\") // mettre votre ID du fichier credentials.csv\nsc.hadoopConfiguration.set(\"fs.s3a.secret.key\", \"TODO\") // mettre votre secret du fichier credentials.csv\n",
      "user": "anonymous",
      "dateUpdated": "2019-01-07 22:31:37.245",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1546896697245_-1513413598",
      "id": "20171217-230735_1688540039",
      "dateCreated": "2019-01-07 22:31:37.245",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md Les fichiers sont stoquees compresses, on a besoin d\u0027un bout de code pour les decompresser en parallel sur les workers au fur et a mesure qu\u0027on les lit depuis S3:",
      "user": "anonymous",
      "dateUpdated": "2019-01-07 22:31:37.247",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eLes fichiers sont stoquees compresses, on a besoin d\u0026rsquo;un bout de code pour les decompresser en parallel sur les workers au fur et a mesure qu\u0026rsquo;on les lit depuis S3:\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546896697246_-1622565412",
      "id": "20181212-102329_808049084",
      "dateCreated": "2019-01-07 22:31:37.246",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import org.apache.spark.input.PortableDataStream\nimport java.util.zip.ZipInputStream\nimport java.io.BufferedReader\nimport java.io.InputStreamReader\n// 20181201000000.export.CSV.zip\nval textRDD \u003d sc.binaryFiles(\"s3a://john-doe-telecom-gdelt2018/20181201[0-9]*.export.CSV.zip\"). // charger quelques fichers via une regex\n   flatMap {  // decompresser les fichiers\n       case (name: String, content: PortableDataStream) \u003d\u003e\n          val zis \u003d new ZipInputStream(content.open)\n          Stream.continually(zis.getNextEntry).\n                takeWhile(_ !\u003d null).\n                flatMap { _ \u003d\u003e\n                    val br \u003d new BufferedReader(new InputStreamReader(zis))\n                    Stream.continually(br.readLine()).takeWhile(_ !\u003d null)\n                }\n    }\ntextRDD.take(1)\n",
      "user": "anonymous",
      "dateUpdated": "2019-01-07 22:31:37.252",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.spark.input.PortableDataStream\nimport java.util.zip.ZipInputStream\nimport java.io.BufferedReader\nimport java.io.InputStreamReader\ntextRDD: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[69] at flatMap at \u003cconsole\u003e:77\nres54: Array[String] \u003d Array(806754250\t20171201\t201712\t2017\t2017.9068\t\t\t\t\t\t\t\t\t\t\tUSA\tUNITED STATES\tUSA\t\t\t\t\t\t\t\t1\t100\t100\t10\t3\t-5.0\t4\t1\t4\t-0.66666666666667\t0\t\t\t\t\t\t\t\t3\tNew Haven, Connecticut, United States\tUS\tUSCT\t\t41.3082\t-72.9282\t209231\t3\tNew Haven, Connecticut, United States\tUS\tUSCT\t\t41.3082\t-72.9282\t209231\t20181201000000\thttps://bismarcktribune.com/news/national/the-latest-immigrant-s-supporters-end-courthouse-protest/article_76d71ef6-d0e0-5e02-ab72-4c8a0d31778e.html)\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546896697251_-1987720379",
      "id": "20171217-232457_1732696781",
      "dateCreated": "2019-01-07 22:31:37.251",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md A vous de jouer ! Utilisez la documentation GDELT(https://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/) et commencez a explorer les donnees via les API Spark.",
      "user": "anonymous",
      "dateUpdated": "2019-01-07 22:31:37.253",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eA vous de jouer ! Utilisez la documentation GDELT(\u003ca href\u003d\"https://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/\"\u003ehttps://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/\u003c/a\u003e) et commencez a explorer les donnees via les API Spark.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1546896697252_-1661832336",
      "id": "20171218-084519_765381887",
      "dateCreated": "2019-01-07 22:31:37.252",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "gdeltExploration",
  "id": "2E2X24ERE",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}