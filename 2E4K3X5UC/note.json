{
  "paragraphs": [
    {
      "text": "%md\n## Creation of RDD from Data\nDans ce notebook nous allons charger les données dans des RDD",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.208",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eCreation of RDD from Data\u003c/h2\u003e\n\u003cp\u003eDans ce notebook nous allons charger les données dans des RDD\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760206_1473452664",
      "id": "20181212-102323_67420128",
      "dateCreated": "2019-01-24 10:22:40.206",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%spark.dep\nz.load(\"com.amazonaws:aws-java-sdk:1.3.10\")\nz.load(\"datastax:spark-cassandra-connector:2.3.0-s_2.11\")\n",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.208",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "res0: org.apache.zeppelin.dep.Dependency \u003d org.apache.zeppelin.dep.Dependency@655ef698\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760208_-431540992",
      "id": "20190121-173833_1225419807",
      "dateCreated": "2019-01-24 10:22:40.208",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import com.amazonaws.services.s3.AmazonS3Client\nimport com.amazonaws.auth.BasicAWSCredentials\nimport org.apache.spark.input.PortableDataStream\nimport java.util.zip.ZipInputStream\nimport java.io.BufferedReader\nimport java.io.InputStreamReader\nimport org.apache.spark.sql.functions.{col, min, max, mean, var_pop, count}\nimport java.io.File\nimport scala.io.Source.{fromFile}\nimport java.net.{HttpURLConnection, URL}\nimport scala.language.postfixOps\nimport scala.sys.process._\nimport com.datastax.spark.connector._\nimport org.apache.spark.sql.cassandra._",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.209",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import com.amazonaws.services.s3.AmazonS3Client\nimport com.amazonaws.auth.BasicAWSCredentials\nimport org.apache.spark.input.PortableDataStream\nimport java.util.zip.ZipInputStream\nimport java.io.BufferedReader\nimport java.io.InputStreamReader\nimport org.apache.spark.sql.functions.{col, min, max, mean, var_pop, count}\nimport java.io.File\nimport scala.io.Source.fromFile\nimport java.net.{HttpURLConnection, URL}\nimport scala.language.postfixOps\nimport scala.sys.process._\nimport com.datastax.spark.connector._\nimport org.apache.spark.sql.cassandra._\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760209_1613936345",
      "id": "20190121-180038_1381998713",
      "dateCreated": "2019-01-24 10:22:40.209",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val bucket_name \u003d \"du-weijia-telecom-gdelt2018\"\nval AWS_ID \u003d \"AKIAJOZH2VNBCRDJMTFA\" //(1) ID du fichier credentials\nval AWS_KEY \u003d \"dg0JP7o/ycrH566aQpLGmzouqqkpQn2p099Inmow\" //(2) Secret du fichier credentials\nval awsClient \u003d new AmazonS3Client(new BasicAWSCredentials(AWS_ID, AWS_KEY))\nsc.hadoopConfiguration.set(\"fs.s3a.access.key\", AWS_ID) \nsc.hadoopConfiguration.set(\"fs.s3a.secret.key\", AWS_KEY) \nsc.hadoopConfiguration.set(\"fs.s3a.connection.maximum\",\"100000\")",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.209",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "bucket_name: String \u003d du-weijia-telecom-gdelt2018\nAWS_ID: String \u003d AKIAJOZH2VNBCRDJMTFA\nAWS_KEY: String \u003d dg0JP7o/ycrH566aQpLGmzouqqkpQn2p099Inmow\nwarning: there was one deprecation warning; re-run with -deprecation for details\nawsClient: com.amazonaws.services.s3.AmazonS3Client \u003d com.amazonaws.services.s3.AmazonS3Client@35c5a770\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760209_750261727",
      "id": "20171217-230735_1688540039",
      "dateCreated": "2019-01-24 10:22:40.209",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md Les fichiers sont stockés compressés, on a besoin d\u0027un bout de code pour les décompresser en parallel sur les workers au fur et a mesure qu\u0027on les lit depuis S3:",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.209",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eLes fichiers sont stockés compressés, on a besoin d\u0026rsquo;un bout de code pour les décompresser en parallel sur les workers au fur et a mesure qu\u0026rsquo;on les lit depuis S3:\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760209_-1929925187",
      "id": "20181212-102329_808049084",
      "dateCreated": "2019-01-24 10:22:40.209",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "def fileDownloader(urlOfFileToDownload: String, file: File) \u003d {\n    val parentDirName \u003d new File(file.getParent())\n    if (! parentDirName.exists()){\n        parentDirName.mkdirs();\n    }\n    val url \u003d new URL(urlOfFileToDownload)\n    val connection \u003d url.openConnection().asInstanceOf[HttpURLConnection]\n    connection.setConnectTimeout(5000)\n    connection.setReadTimeout(5000)\n    connection.connect()\n    if(connection.getResponseCode \u003e\u003d 400){\n        println(\"error\")\n    }\n    else {\n        url #\u003e file !!\n    }\n}",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.209",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "fileDownloader: (urlOfFileToDownload: String, file: java.io.File)Any\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760209_-21385429",
      "id": "20190121-181413_1774031819",
      "dateCreated": "2019-01-24 10:22:40.209",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "def RDDDownloader(fileName: String): org.apache.spark.rdd.RDD[String] \u003d \n{\n    val resultRDD \u003d sc.binaryFiles(fileName). // charger quelques fichers via une regex\n    flatMap {  // decompresser les fichiers\n        case (name: String, content: PortableDataStream) \u003d\u003e\n            try {\n                val zis \u003d new ZipInputStream(content.open)\n                Stream.continually(zis.getNextEntry).\n                    takeWhile(_ !\u003d null).\n                    flatMap { _ \u003d\u003e\n                        val br \u003d new BufferedReader(new InputStreamReader(zis))\n                        Stream.continually(br.readLine()).takeWhile(_ !\u003d null)\n                    }\n            } catch {\n                case e : Exception \u003d\u003e\n                None\n            }\n    }\n    return resultRDD\n}",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.210",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "RDDDownloader: (fileName: String)org.apache.spark.rdd.RDD[String]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760210_-773878148",
      "id": "20190122-092242_1695948710",
      "dateCreated": "2019-01-24 10:22:40.210",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val local_path \u003d System.getProperty(\"user.dir\")\n\nfileDownloader(\"https://www.gdeltproject.org/data/lookups/CAMEO.knowngroup.txt\", new File(local_path + \"/CAMEO.knowngroup.txt\"))\nnew AmazonS3Client(new BasicAWSCredentials(AWS_ID, AWS_KEY)).putObject(bucket_name, \"CAMEO.knowngroup.txt\", local_path + \"/CAMEO.knowngroup.txt\")\n\nfileDownloader(\"https://www.gdeltproject.org/data/lookups/CAMEO.country.txt\", new File(local_path + \"/CAMEO.country.txt\"))\nnew AmazonS3Client(new BasicAWSCredentials(AWS_ID, AWS_KEY)).putObject(bucket_name, \"CAMEO.country.txt\", local_path + \"/CAMEO.country.txt\")",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.210",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "local_path: String \u003d /mnt/var/lib/zeppelin\nres11: Any \u003d \"\"\nwarning: there was one deprecation warning; re-run with -deprecation for details\nres12: com.amazonaws.services.s3.model.PutObjectResult \u003d com.amazonaws.services.s3.model.PutObjectResult@2649abe7\nres13: Any \u003d \"\"\nwarning: there was one deprecation warning; re-run with -deprecation for details\nres14: com.amazonaws.services.s3.model.PutObjectResult \u003d com.amazonaws.services.s3.model.PutObjectResult@e21e836\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760210_616511958",
      "id": "20190121-181435_2076071535",
      "dateCreated": "2019-01-24 10:22:40.210",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Export Events\nval eventsRDD01 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/201801*.export.CSV.zip\")\nval eventsRDD02 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/201802*.export.CSV.zip\")\nval eventsRDD03 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/201803*.export.CSV.zip\")\nval eventsRDD04 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/201804*.export.CSV.zip\")\nval eventsRDD050 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/2018050*.export.CSV.zip\")\nval eventsRDD051 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/2018051*.export.CSV.zip\")\nval eventsRDD052 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/2018052*.export.CSV.zip\")\nval eventsRDD060 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/2018060*.export.CSV.zip\")\nval eventsRDD062 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/2018062*.export.CSV.zip\")\nval eventsRDD063 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/2018063*.export.CSV.zip\")\nval eventsRDD07 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/201807*.export.CSV.zip\")\nval eventsRDD08 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/201808*.export.CSV.zip\")\nval eventsRDD09 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/201809*.export.CSV.zip\")\nval eventsRDD10 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/201810*.export.CSV.zip\")\nval eventsRDD11 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/201811*.export.CSV.zip\")\nval eventsRDD12 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/events/201812*.export.CSV.zip\")",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.210",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "eventsRDD01: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[1] at flatMap at \u003cconsole\u003e:49\neventsRDD02: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[3] at flatMap at \u003cconsole\u003e:49\neventsRDD03: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[5] at flatMap at \u003cconsole\u003e:49\neventsRDD04: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[7] at flatMap at \u003cconsole\u003e:49\neventsRDD050: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[9] at flatMap at \u003cconsole\u003e:49\neventsRDD051: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[11] at flatMap at \u003cconsole\u003e:49\neventsRDD052: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[13] at flatMap at \u003cconsole\u003e:49\neventsRDD060: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[15] at flatMap at \u003cconsole\u003e:49\neventsRDD062: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[17] at flatMap at \u003cconsole\u003e:49\neventsRDD063: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[19] at flatMap at \u003cconsole\u003e:49\neventsRDD07: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[21] at flatMap at \u003cconsole\u003e:49\neventsRDD08: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[23] at flatMap at \u003cconsole\u003e:49\neventsRDD09: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[25] at flatMap at \u003cconsole\u003e:49\neventsRDD10: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[27] at flatMap at \u003cconsole\u003e:49\neventsRDD11: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[29] at flatMap at \u003cconsole\u003e:49\neventsRDD12: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[31] at flatMap at \u003cconsole\u003e:49\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760210_1197313892",
      "id": "20190124-024702_1935596288",
      "dateCreated": "2019-01-24 10:22:40.210",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Export mentions_english\nval mentions_englishRDD01 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions_english/201801*.CSV.zip\")\nval mentions_englishRDD02 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions_english/201802*.CSV.zip\")\nval mentions_englishRDD030 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions_english/2018030*.CSV.zip\")\nval mentions_englishRDD031 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions_english/2018031*.CSV.zip\")\nval mentions_englishRDD032 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions_english/2018032*.CSV.zip\")\nval mentions_englishRDD04 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions_english/201804*.CSV.zip\")\nval mentions_englishRDD05 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions_english/201805*.CSV.zip\")\nval mentions_englishRDD06 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions_english/201806*.CSV.zip\")\nval mentions_englishRDD07 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions_english/201807*.CSV.zip\")\nval mentions_englishRDD08 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions_english/201808*.CSV.zip\")\nval mentions_englishRDD09 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions_english/201809*.CSV.zip\")\nval mentions_englishRDD10 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions_english/201810*.CSV.zip\")\nval mentions_englishRDD11 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions_english/201811*.CSV.zip\")\nval mentions_englishRDD12 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions_english/201812*.CSV.zip\")",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.210",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "mentions_englishRDD01: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[33] at flatMap at \u003cconsole\u003e:49\nmentions_englishRDD02: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[35] at flatMap at \u003cconsole\u003e:49\nmentions_englishRDD030: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[37] at flatMap at \u003cconsole\u003e:49\nmentions_englishRDD031: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[39] at flatMap at \u003cconsole\u003e:49\nmentions_englishRDD032: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[41] at flatMap at \u003cconsole\u003e:49\nmentions_englishRDD04: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[43] at flatMap at \u003cconsole\u003e:49\nmentions_englishRDD05: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[45] at flatMap at \u003cconsole\u003e:49\nmentions_englishRDD06: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[47] at flatMap at \u003cconsole\u003e:49\nmentions_englishRDD07: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[49] at flatMap at \u003cconsole\u003e:49\nmentions_englishRDD08: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[51] at flatMap at \u003cconsole\u003e:49\nmentions_englishRDD09: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[53] at flatMap at \u003cconsole\u003e:49\nmentions_englishRDD10: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[55] at flatMap at \u003cconsole\u003e:49\nmentions_englishRDD11: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[57] at flatMap at \u003cconsole\u003e:49\nmentions_englishRDD12: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[59] at flatMap at \u003cconsole\u003e:49\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760210_584050177",
      "id": "20190124-024712_864274114",
      "dateCreated": "2019-01-24 10:22:40.210",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Export Mentions\nval mentionsRDD01 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions/201801*.CSV.zip\")\nval mentionsRDD02 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions/201802*.CSV.zip\")\nval mentionsRDD03 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions/201803*.CSV.zip\")\nval mentionsRDD04 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions/201804*.CSV.zip\")\nval mentionsRDD05 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions/201805*.CSV.zip\")\nval mentionsRDD06 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions/201806*.CSV.zip\")\nval mentionsRDD07 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions/201807*.CSV.zip\")\nval mentionsRDD08 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions/201808*.CSV.zip\")\nval mentionsRDD090 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions/2018090*.CSV.zip\")\nval mentionsRDD092 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions/2018092*.CSV.zip\")\nval mentionsRDD093 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions/2018093*.CSV.zip\")\nval mentionsRDD10 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions/201810*.CSV.zip\")\nval mentionsRDD11 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions/201811*.CSV.zip\")\nval mentionsRDD12 \u003d RDDDownloader(\"s3a://\" + bucket_name + \"/mentions/201812*.CSV.zip\")",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.210",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "mentionsRDD01: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[61] at flatMap at \u003cconsole\u003e:49\nmentionsRDD02: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[63] at flatMap at \u003cconsole\u003e:49\nmentionsRDD03: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[65] at flatMap at \u003cconsole\u003e:49\nmentionsRDD04: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[67] at flatMap at \u003cconsole\u003e:49\nmentionsRDD05: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[69] at flatMap at \u003cconsole\u003e:49\nmentionsRDD06: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[71] at flatMap at \u003cconsole\u003e:49\nmentionsRDD07: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[73] at flatMap at \u003cconsole\u003e:49\nmentionsRDD08: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[75] at flatMap at \u003cconsole\u003e:49\nmentionsRDD090: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[77] at flatMap at \u003cconsole\u003e:49\nmentionsRDD092: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[79] at flatMap at \u003cconsole\u003e:49\nmentionsRDD093: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[81] at flatMap at \u003cconsole\u003e:49\nmentionsRDD10: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[83] at flatMap at \u003cconsole\u003e:49\nmentionsRDD11: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[85] at flatMap at \u003cconsole\u003e:49\nmentionsRDD12: org.apache.spark.rdd.RDD[String] \u003d MapPartitionsRDD[87] at flatMap at \u003cconsole\u003e:49\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760210_-1343508085",
      "id": "20190124-024722_753454035",
      "dateCreated": "2019-01-24 10:22:40.210",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// cache\n\neventsRDD01.cache()\neventsRDD02.cache()\neventsRDD03.cache()\neventsRDD04.cache()\neventsRDD050.cache()\neventsRDD051.cache()\neventsRDD052.cache()\neventsRDD060.cache()\neventsRDD062.cache()\neventsRDD063.cache()\neventsRDD07.cache()\neventsRDD08.cache()\neventsRDD09.cache()\neventsRDD10.cache()\neventsRDD11.cache()\neventsRDD12.cache()\n\nmentionsRDD01.cache()\nmentionsRDD02.cache()\nmentionsRDD03.cache()\nmentionsRDD04.cache()\nmentionsRDD05.cache()\nmentionsRDD06.cache()\nmentionsRDD07.cache()\nmentionsRDD08.cache()\nmentionsRDD090.cache()\nmentionsRDD092.cache()\n//mentionsRDD091.cache()\nmentionsRDD093.cache()\nmentionsRDD10.cache()\nmentionsRDD11.cache()\nmentionsRDD12.cache()\n\n\nmentions_englishRDD01.cache()\nmentions_englishRDD02.cache()\nmentions_englishRDD030.cache()\nmentions_englishRDD031.cache()\nmentions_englishRDD032.cache()\nmentions_englishRDD04.cache()\nmentions_englishRDD05.cache()\nmentions_englishRDD06.cache()\nmentions_englishRDD07.cache()\nmentions_englishRDD08.cache()\nmentions_englishRDD09.cache()\nmentions_englishRDD10.cache()\nmentions_englishRDD11.cache()\nmentions_englishRDD12.cache()",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.211",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "res130: eventsRDD01.type \u003d MapPartitionsRDD[1] at flatMap at \u003cconsole\u003e:49\nres131: eventsRDD02.type \u003d MapPartitionsRDD[3] at flatMap at \u003cconsole\u003e:49\nres132: eventsRDD03.type \u003d MapPartitionsRDD[5] at flatMap at \u003cconsole\u003e:49\nres133: eventsRDD04.type \u003d MapPartitionsRDD[7] at flatMap at \u003cconsole\u003e:49\nres134: eventsRDD050.type \u003d MapPartitionsRDD[9] at flatMap at \u003cconsole\u003e:49\nres135: eventsRDD051.type \u003d MapPartitionsRDD[11] at flatMap at \u003cconsole\u003e:49\nres136: eventsRDD052.type \u003d MapPartitionsRDD[13] at flatMap at \u003cconsole\u003e:49\nres137: eventsRDD060.type \u003d MapPartitionsRDD[15] at flatMap at \u003cconsole\u003e:49\nres138: eventsRDD062.type \u003d MapPartitionsRDD[17] at flatMap at \u003cconsole\u003e:49\nres139: eventsRDD063.type \u003d MapPartitionsRDD[19] at flatMap at \u003cconsole\u003e:49\nres140: eventsRDD07.type \u003d MapPartitionsRDD[21] at flatMap at \u003cconsole\u003e:49\nres141: eventsRDD08.type \u003d MapPartitionsRDD[23] at flatMap at \u003cconsole\u003e:49\nres142: eventsRDD09.type \u003d MapPartitionsRDD[25] at flatMap at \u003cconsole\u003e:49\nres143: eventsRDD10.type \u003d MapPartitionsRDD[27] at flatMap at \u003cconsole\u003e:49\nres144: eventsRDD11.type \u003d MapPartitionsRDD[29] at flatMap at \u003cconsole\u003e:49\nres145: eventsRDD12.type \u003d MapPartitionsRDD[31] at flatMap at \u003cconsole\u003e:49\nres146: mentionsRDD01.type \u003d MapPartitionsRDD[61] at flatMap at \u003cconsole\u003e:49\nres147: mentionsRDD02.type \u003d MapPartitionsRDD[63] at flatMap at \u003cconsole\u003e:49\nres148: mentionsRDD03.type \u003d MapPartitionsRDD[65] at flatMap at \u003cconsole\u003e:49\nres149: mentionsRDD04.type \u003d MapPartitionsRDD[67] at flatMap at \u003cconsole\u003e:49\nres150: mentionsRDD05.type \u003d MapPartitionsRDD[69] at flatMap at \u003cconsole\u003e:49\nres151: mentionsRDD06.type \u003d MapPartitionsRDD[71] at flatMap at \u003cconsole\u003e:49\nres152: mentionsRDD07.type \u003d MapPartitionsRDD[73] at flatMap at \u003cconsole\u003e:49\nres153: mentionsRDD08.type \u003d MapPartitionsRDD[75] at flatMap at \u003cconsole\u003e:49\nres154: mentionsRDD090.type \u003d MapPartitionsRDD[77] at flatMap at \u003cconsole\u003e:49\nres155: mentionsRDD092.type \u003d MapPartitionsRDD[79] at flatMap at \u003cconsole\u003e:49\nres157: mentionsRDD093.type \u003d MapPartitionsRDD[81] at flatMap at \u003cconsole\u003e:49\nres158: mentionsRDD10.type \u003d MapPartitionsRDD[83] at flatMap at \u003cconsole\u003e:49\nres159: mentionsRDD11.type \u003d MapPartitionsRDD[85] at flatMap at \u003cconsole\u003e:49\nres160: mentionsRDD12.type \u003d MapPartitionsRDD[87] at flatMap at \u003cconsole\u003e:49\nres161: mentions_englishRDD01.type \u003d MapPartitionsRDD[33] at flatMap at \u003cconsole\u003e:49\nres162: mentions_englishRDD02.type \u003d MapPartitionsRDD[35] at flatMap at \u003cconsole\u003e:49\nres163: mentions_englishRDD030.type \u003d MapPartitionsRDD[37] at flatMap at \u003cconsole\u003e:49\nres164: mentions_englishRDD031.type \u003d MapPartitionsRDD[39] at flatMap at \u003cconsole\u003e:49\nres165: mentions_englishRDD032.type \u003d MapPartitionsRDD[41] at flatMap at \u003cconsole\u003e:49\nres166: mentions_englishRDD04.type \u003d MapPartitionsRDD[43] at flatMap at \u003cconsole\u003e:49\nres167: mentions_englishRDD05.type \u003d MapPartitionsRDD[45] at flatMap at \u003cconsole\u003e:49\nres168: mentions_englishRDD06.type \u003d MapPartitionsRDD[47] at flatMap at \u003cconsole\u003e:49\nres169: mentions_englishRDD07.type \u003d MapPartitionsRDD[49] at flatMap at \u003cconsole\u003e:49\nres170: mentions_englishRDD08.type \u003d MapPartitionsRDD[51] at flatMap at \u003cconsole\u003e:49\nres171: mentions_englishRDD09.type \u003d MapPartitionsRDD[53] at flatMap at \u003cconsole\u003e:49\nres172: mentions_englishRDD10.type \u003d MapPartitionsRDD[55] at flatMap at \u003cconsole\u003e:49\nres173: mentions_englishRDD11.type \u003d MapPartitionsRDD[57] at flatMap at \u003cconsole\u003e:49\nres174: mentions_englishRDD12.type \u003d MapPartitionsRDD[59] at flatMap at \u003cconsole\u003e:49\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760210_-442499370",
      "id": "20190124-025747_24201492",
      "dateCreated": "2019-01-24 10:22:40.210",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Try the events (5 to 6)  not sure on them\nprintf(\"Count \u003d %d, file n°%d\", mentionsRDD092.count(), 11)",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.211",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Count \u003d 2077122, file n°11"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760211_-1330568280",
      "id": "20190123-205446_1830563629",
      "dateCreated": "2019-01-24 10:22:40.211",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val cachedEvents \u003d eventsRDD01.\n                    union(eventsRDD02).\n                    union(eventsRDD03).\n                    union(eventsRDD04).\n                    union(eventsRDD050).\n                    union(eventsRDD051).\n                    union(eventsRDD052).\n                    union(eventsRDD060).\n                    union(eventsRDD062).\n                    union(eventsRDD063).\n                    union(eventsRDD07).\n                    union(eventsRDD08).\n                    union(eventsRDD09).\n                    union(eventsRDD10).\n                    union(eventsRDD11).\n                    union(eventsRDD12).cache()",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.211",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "cachedEvents: org.apache.spark.rdd.RDD[String] \u003d UnionRDD[419] at union at \u003cconsole\u003e:99\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760211_1714089347",
      "id": "20190124-030936_240300492",
      "dateCreated": "2019-01-24 10:22:40.211",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val cachedMentions \u003d mentionsRDD01.\n                    union(mentionsRDD02).\n                    union(mentionsRDD03).\n                    union(mentionsRDD04).\n                    union(mentionsRDD05).\n                    union(mentionsRDD06).\n                    union(mentionsRDD07).\n                    union(mentionsRDD08).\n                    union(mentionsRDD090).\n                    union(mentionsRDD092).\n                    union(mentionsRDD093).\n                    union(mentionsRDD10).\n                    union(mentionsRDD11).\n                    union(mentionsRDD12).cache()",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.211",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "cachedMentions: org.apache.spark.rdd.RDD[String] \u003d UnionRDD[432] at union at \u003cconsole\u003e:93\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760211_946530402",
      "id": "20190124-030658_2128471067",
      "dateCreated": "2019-01-24 10:22:40.211",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val cachedMentions_english \u003d mentions_englishRDD01.\n                    union(mentions_englishRDD02).\n                    union(mentions_englishRDD030).\n                    union(mentions_englishRDD031).\n                    union(mentions_englishRDD032).\n                    union(mentions_englishRDD04).\n                    union(mentions_englishRDD05).\n                    union(mentions_englishRDD06).\n                    union(mentions_englishRDD07).\n                    union(mentions_englishRDD08).\n                    union(mentions_englishRDD09).\n                    union(mentions_englishRDD10).\n                    union(mentions_englishRDD11).\n                    union(mentions_englishRDD12).cache()",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.212",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "cachedMentions_english: org.apache.spark.rdd.RDD[String] \u003d UnionRDD[445] at union at \u003cconsole\u003e:93\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760212_880702458",
      "id": "20190123-210719_793403859",
      "dateCreated": "2019-01-24 10:22:40.212",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "case class Event(GLOBALEVENTID: Int,\nSQLDATE: String,\nMonthYear: String,\nYear: Int,\nFractionDate: Double,\nActor1Code: String,\nActor1Name: String,\nActor1CountryCode: String,\nActor1KnownGroupCode: String,\nActor1EthnicCode: String,\nActor1Religion1Code: String,\nActor1Religion2Code: String,\nActor1Type1Code: String,\nActor1Type2Code: String,\nActor1Type3Code: String,\nActor2Code: String,\nActor2Name: String,\nActor2CountryCode: String,\nActor2KnownGroupCode: String,\nActor2EthnicCode: String,\nActor2Religion1Code: String,\nActor2Religion2Code: String,\nActor2Type1Code: String,\nActor2Type2Code: String,\nActor2Type3Code: String,\nIsRootEvent: Int,\nEventCode: String,\nEventBaseCode: String,\nEventRootCode: String,\nQuadClass: Int,\nGoldsteinScale: Double,\nNumMentions: Int,\nNumSources: Int,\nNumArticles: Int,\nAvgTone: Double,\nActor1Geo_Type: Int,\nActor1Geo_FullName: String,\nActor1Geo_CountryCode: String,\nActor1Geo_ADM1Code: String,\nActor1Geo_ADM2Code: String,\nActor1Geo_Lat: Double,\nActor1Geo_Long: Double,\nActor1Geo_FeatureID: String,\nActor2Geo_Type: Int,\nActor2Geo_FullName: String,\nActor2Geo_CountryCode: String,\nActor2Geo_ADM1Code: String,\nActor2Geo_ADM2Code: String,\nActor2Geo_Lat: Double,\nActor2Geo_Long: Double,\nActor2Geo_FeatureID: String,\nActionGeo_Type: Int,\nActionGeo_FullName: String,\nActionGeo_CountryCode: String,\nActionGeo_ADM1Code: String,\nActionGeo_ADM2Code: String,\nActionGeo_Lat: Double,\nActionGeo_Long: Double,\nActionGeo_FeatureID: String,\nDATEADDED: String,\nSOURCEURL: String)",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.212",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "defined class Event\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760212_1116822367",
      "id": "20190107-095023_1048093380",
      "dateCreated": "2019-01-24 10:22:40.212",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "case class Mention(GLOBALEVENTID: Int,\nEventTimeDate: String,\nMentionTimeDate: String,\nMentionType: Int,\nMentionSourceName: String,\nMentionIdentifier: String,\nSentenceID: Int,\nActor1CharOffset: Int,\nActor2CharOffset: Int,\nActionCharOffset: Int,\nInRawText: Int,\nConfidence: Int,\nMentionDocLen: Int,\nMentionDocTone: Double,\nMentionDocTranslationInfo: String)//,\n//Extras: String)",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.212",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "defined class Mention\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760212_-1555039530",
      "id": "20190109-085959_371186108",
      "dateCreated": "2019-01-24 10:22:40.212",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import java.text.SimpleDateFormat\n\ndef toDouble(s : String): Double \u003d {\n    if (s.isEmpty) 0  \n    else {\n        try {\n            s.toDouble\n        } catch {\n            case e: Exception \u003d\u003e 0\n        }\n    }\n}\n\ndef toInt(s : String): Int \u003d {\n    if (s.isEmpty) 0  \n    else {\n        try {\n            s.toInt\n        } catch {\n            case e: Exception \u003d\u003e 0\n        }\n    }\n}\n\ndef toBigInt(s : String): BigInt \u003d {\n    if (s.isEmpty) BigInt(0) \n    else {\n        try {\n            BigInt(s)\n        } catch {\n            case e: Exception \u003d\u003e BigInt(0) \n        }\n    }\n}\n \nval inputFormat_ymd \u003d new SimpleDateFormat(\"yyyyMMdd\")\nval outputFormat_ymd \u003d new SimpleDateFormat(\"yyyy-MM-dd\")\n\nval inputFormat_ym \u003d new SimpleDateFormat(\"yyyyMM\")\nval outputFormat_ym \u003d new SimpleDateFormat(\"yyyy-MM\")\n\nval inputFormat_ymdhms \u003d new SimpleDateFormat(\"yyyyMMddhhmmss\")\nval outputFormat_ymdhms \u003d new SimpleDateFormat(\"yyyy-MM-dd hh:mm:ss\")\n    \ndef parse_date(s : String, inputFormat : SimpleDateFormat, outputFormat : SimpleDateFormat):\n    String \u003d if (s.isEmpty) s else  outputFormat.format(inputFormat.parse(s))   \n\n\ncachedEvents.map(_.split(\"\\t\")).filter(_.length\u003d\u003d61).map(\n    e\u003d\u003e Event(\n        toInt(e(0)),parse_date(e(1), inputFormat_ymd, outputFormat_ymd),parse_date(e(2), inputFormat_ym, outputFormat_ym),toInt(e(3)),toDouble(e(4)),e(5),e(6),e(7),e(8),e(9),e(10),e(11),e(12),e(13),e(14),e(15),e(16),e(17),e(18),e(19),e(20),\n        e(21),e(22),e(23),e(24),toInt(e(25)),e(26),e(27),e(28),toInt(e(29)),toDouble(e(30)),toInt(e(31)),toInt(e(32)),toInt(e(33)),toDouble(e(34)),toInt(e(35)),e(36),e(37),e(38),e(39),toDouble(e(40)),\n        toDouble(e(41)),e(42),toInt(e(43)),e(44),e(45),e(46),e(47),toDouble(e(48)),toDouble(e(49)),e(50),toInt(e(51)),e(52),e(53),e(54),e(55),toDouble(e(56)),toDouble(e(57)),e(58),parse_date(e(59),inputFormat_ymdhms, outputFormat_ymdhms),e(60))\n\n).toDS.createOrReplaceTempView(\"events\")",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.213",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import java.text.SimpleDateFormat\ntoDouble: (s: String)Double\ntoInt: (s: String)Int\ntoBigInt: (s: String)BigInt\ninputFormat_ymd: java.text.SimpleDateFormat \u003d java.text.SimpleDateFormat@ef87e460\noutputFormat_ymd: java.text.SimpleDateFormat \u003d java.text.SimpleDateFormat@f67a0200\ninputFormat_ym: java.text.SimpleDateFormat \u003d java.text.SimpleDateFormat@d55c4fe0\noutputFormat_ym: java.text.SimpleDateFormat \u003d java.text.SimpleDateFormat@d62d344d\ninputFormat_ymdhms: java.text.SimpleDateFormat \u003d java.text.SimpleDateFormat@88c7dd60\noutputFormat_ymdhms: java.text.SimpleDateFormat \u003d java.text.SimpleDateFormat@e863f5a0\nparse_date: (s: String, inputFormat: java.text.SimpleDateFormat, outputFormat: java.text.SimpleDateFormat)String\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760213_62714563",
      "id": "20190120-164044_87848048",
      "dateCreated": "2019-01-24 10:22:40.213",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "var events \u003d cachedEvents.map(_.split(\"\\t\")).filter(_.length\u003d\u003d61).map(\n    e\u003d\u003e Event(\n        toInt(e(0)),parse_date(e(1), inputFormat_ymd, outputFormat_ymd),parse_date(e(2), inputFormat_ym, outputFormat_ym),toInt(e(3)),toDouble(e(4)),e(5),e(6),e(7),e(8),e(9),e(10),e(11),e(12),e(13),e(14),e(15),e(16),e(17),e(18),e(19),e(20),\n        e(21),e(22),e(23),e(24),toInt(e(25)),e(26),e(27),e(28),toInt(e(29)),toDouble(e(30)),toInt(e(31)),toInt(e(32)),toInt(e(33)),toDouble(e(34)),toInt(e(35)),e(36),e(37),e(38),e(39),toDouble(e(40)),\n        toDouble(e(41)),e(42),toInt(e(43)),e(44),e(45),e(46),e(47),toDouble(e(48)),toDouble(e(49)),e(50),toInt(e(51)),e(52),e(53),e(54),e(55),toDouble(e(56)),toDouble(e(57)),e(58),parse_date(e(59),inputFormat_ymdhms, outputFormat_ymdhms),e(60))\n\n).toDF()\n\nevents \u003d events.withColumn(\"SQLDate_date\",$\"SQLDATE\".cast(\"date\"))",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.213",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "events: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 59 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 60 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760213_977399372",
      "id": "20190122-150307_1363487609",
      "dateCreated": "2019-01-24 10:22:40.213",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "var df1 \u003d cachedMentions.map(_.split(\"\\t\")).filter(_.length\u003d\u003d15).map(\n    e\u003d\u003e Mention(\n        toInt(e(0)),parse_date(e(1),inputFormat_ymdhms, outputFormat_ymdhms),parse_date(e(2),inputFormat_ymdhms, outputFormat_ymdhms),toInt(e(3)),e(4),e(5),toInt(e(6)),toInt(e(7)),toInt(e(8)),toInt(e(9)),toInt(e(10)),toInt(e(11)),toInt(e(12)),toDouble(e(13)), e(14).substring(6, 9))\n).toDF()\n\nvar df2 \u003d cachedMentions_english.map(_.split(\"\\t\")).filter(_.length\u003d\u003d14).map(\n    e\u003d\u003e Mention(\n        toInt(e(0)),parse_date(e(1),inputFormat_ymdhms, outputFormat_ymdhms),parse_date(e(2),inputFormat_ymdhms, outputFormat_ymdhms),toInt(e(3)),e(4),e(5),toInt(e(6)),toInt(e(7)),toInt(e(8)),toInt(e(9)),toInt(e(10)),toInt(e(11)),toInt(e(12)),toDouble(e(13)),\"eng\")\n).toDF()\n\nvar mentions \u003d df1.union(df2).toDF()",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.214",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "df1: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, EventTimeDate: string ... 13 more fields]\ndf2: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, EventTimeDate: string ... 13 more fields]\nmentions: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, EventTimeDate: string ... 13 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760213_1197630917",
      "id": "20190122-150317_187399109",
      "dateCreated": "2019-01-24 10:22:40.214",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val Cameolocation \u003d \"s3a://\" + bucket_name + \"/CameoFolder\"\nval file_Country \u003d \"CAMEO.country.txt\"\nval file_Ethnic \u003d \"CAMEO.ethnic.txt\"\nval file_Eventcodes \u003d \"CAMEO.eventcodes.txt\"\nval file_Knowngroup \u003d \"CAMEO.knowngroup.txt\"\nval file_Religion \u003d \"CAMEO.religion.txt\"\nval file_Type \u003d \"CAMEO.type.txt\"\nval file_Quad \u003d \"CAMEO.QuadClass.txt\"\nval file_GeoType \u003d \"CAMEO.GeoType.txt\"\nval file_FIPSCountryCode \u003d \"CAMEO.FIPSCountyCode.txt\"\nval file_Language \u003d \"CAMEO.language.txt\"",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.214",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Cameolocation: String \u003d s3a://du-weijia-telecom-gdelt2018/CameoFolder\nfile_Country: String \u003d CAMEO.country.txt\nfile_Ethnic: String \u003d CAMEO.ethnic.txt\nfile_Eventcodes: String \u003d CAMEO.eventcodes.txt\nfile_Knowngroup: String \u003d CAMEO.knowngroup.txt\nfile_Religion: String \u003d CAMEO.religion.txt\nfile_Type: String \u003d CAMEO.type.txt\nfile_Quad: String \u003d CAMEO.QuadClass.txt\nfile_GeoType: String \u003d CAMEO.GeoType.txt\nfile_FIPSCountryCode: String \u003d CAMEO.FIPSCountyCode.txt\nfile_Language: String \u003d CAMEO.language.txt\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760214_1756749323",
      "id": "20190122-150325_1253504812",
      "dateCreated": "2019-01-24 10:22:40.214",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// creation of the mapping dataset\nval country_transco \u003d spark.read.\n    format(\"csv\").\n    option(\"header\", true).\n    option(\"delimiter\", \"\\t\").\n    load(Cameolocation+\"/\"+file_Country)\n\nval ethnic_transco \u003d spark.read.\n    format(\"csv\").\n    option(\"header\", true).\n    option(\"delimiter\", \"\\t\").\n    load(Cameolocation+\"/\"+file_Ethnic)\n\nval eventCodes_transco \u003d spark.read.\n    format(\"csv\").\n    option(\"header\", true).\n    option(\"delimiter\", \"\\t\").\n    load(Cameolocation+\"/\"+file_Eventcodes)\n\nval group_transco \u003d spark.read.\n    format(\"csv\").\n    option(\"header\", true).\n    option(\"delimiter\", \"\\t\").\n    load(Cameolocation+\"/\"+file_Knowngroup)\n\nval religion_transco \u003d spark.read.\n    format(\"csv\").\n    option(\"header\", true).\n    option(\"delimiter\", \"\\t\").\n    load(Cameolocation+\"/\"+file_Religion)\n\nval type_transco \u003d spark.read.\n    format(\"csv\").\n    option(\"header\", true).\n    option(\"delimiter\", \"\\t\").\n    load(Cameolocation+\"/\"+file_Type)\n\nval quad_transco \u003d spark.read.\n    format(\"csv\").\n    option(\"header\", true).\n    option(\"delimiter\", \"\\t\").\n    load(Cameolocation+\"/\"+file_Quad)\n    \nval geoType_transco \u003d spark.read.\n    format(\"csv\").\n    option(\"header\", true).\n    option(\"delimiter\", \"\\t\").\n    load(Cameolocation+\"/\"+file_GeoType)\n    \nval FIPS_transco \u003d spark.read.\n    format(\"csv\").\n    option(\"header\", true).\n    option(\"delimiter\", \"\\t\").\n    load(Cameolocation+\"/\"+file_FIPSCountryCode)\n    \nval language_transco \u003d spark.read.\n    format(\"csv\").\n    option(\"header\", true).\n    option(\"delimiter\", \"\\t\").\n    load(Cameolocation+\"/\"+file_Language)\n    \n",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.215",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "country_transco: org.apache.spark.sql.DataFrame \u003d [CODE: string, LABEL: string]\nethnic_transco: org.apache.spark.sql.DataFrame \u003d [CODE: string, LABEL: string]\neventCodes_transco: org.apache.spark.sql.DataFrame \u003d [CODE: string, LABEL: string]\ngroup_transco: org.apache.spark.sql.DataFrame \u003d [CODE: string, LABEL: string]\nreligion_transco: org.apache.spark.sql.DataFrame \u003d [CODE: string, LABEL: string]\ntype_transco: org.apache.spark.sql.DataFrame \u003d [CODE: string, LABEL: string]\nquad_transco: org.apache.spark.sql.DataFrame \u003d [CODE: string, LABEL: string]\ngeoType_transco: org.apache.spark.sql.DataFrame \u003d [CODE: string, LABEL: string]\nFIPS_transco: org.apache.spark.sql.DataFrame \u003d [LABEL: string, CODE: string]\nlanguage_transco: org.apache.spark.sql.DataFrame \u003d [CODE: string, LABEL: string]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760215_-1788203406",
      "id": "20190122-150615_2062727155",
      "dateCreated": "2019-01-24 10:22:40.215",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "events \u003d events.join(country_transco, events(\"Actor1CountryCode\")\u003d\u003d\u003dcountry_transco(\"CODE\"), \"left\").withColumn(\"Actor1CountryName\", col(\"LABEL\")).drop(country_transco.columns: _*)\nevents \u003d events.join(country_transco, events(\"Actor2CountryCode\")\u003d\u003d\u003dcountry_transco(\"CODE\"), \"left\").withColumn(\"Actor2CountryName\", col(\"LABEL\")).drop(country_transco.columns: _*)\n\nevents \u003d events.join(ethnic_transco, events(\"Actor1EthnicCode\")\u003d\u003d\u003dethnic_transco(\"CODE\"), \"left\").withColumn(\"Actor1EthnicName\", col(\"LABEL\")).drop(ethnic_transco.columns: _*)\nevents \u003d events.join(ethnic_transco, events(\"Actor2EthnicCode\")\u003d\u003d\u003dethnic_transco(\"CODE\"), \"left\").withColumn(\"Actor2EthnicName\", col(\"LABEL\")).drop(ethnic_transco.columns: _*)\n\nevents \u003d events.join(eventCodes_transco, events(\"EventCode\")\u003d\u003d\u003deventCodes_transco(\"CODE\"), \"left\").withColumn(\"EventCodeDesc\", col(\"LABEL\")).drop(eventCodes_transco.columns: _*)\nevents \u003d events.join(eventCodes_transco, events(\"EventBaseCode\")\u003d\u003d\u003deventCodes_transco(\"CODE\"), \"left\").withColumn(\"EventBaseCodeDesc\", col(\"LABEL\")).drop(eventCodes_transco.columns: _*)\nevents \u003d events.join(eventCodes_transco, events(\"EventRootCode\")\u003d\u003d\u003deventCodes_transco(\"CODE\"), \"left\").withColumn(\"EventRootCodeDesc\", col(\"LABEL\")).drop(eventCodes_transco.columns: _*)\n\nevents \u003d events.join(group_transco, events(\"Actor1KnownGroupCode\")\u003d\u003d\u003dgroup_transco(\"CODE\"), \"left\").withColumn(\"Actor1KnownGroupName\", col(\"LABEL\")).drop(group_transco.columns: _*)\nevents \u003d events.join(group_transco, events(\"Actor2KnownGroupCode\")\u003d\u003d\u003dgroup_transco(\"CODE\"), \"left\").withColumn(\"Actor2KnownGroupName\", col(\"LABEL\")).drop(group_transco.columns: _*)\n\nevents \u003d events.join(religion_transco, events(\"Actor1Religion1Code\")\u003d\u003d\u003dreligion_transco(\"CODE\"), \"left\").withColumn(\"Actor1Religion1Name\", col(\"LABEL\")).drop(religion_transco.columns: _*)\nevents \u003d events.join(religion_transco, events(\"Actor1Religion2Code\")\u003d\u003d\u003dreligion_transco(\"CODE\"), \"left\").withColumn(\"Actor1Religion2Name\", col(\"LABEL\")).drop(religion_transco.columns: _*)\nevents \u003d events.join(religion_transco, events(\"Actor2Religion1Code\")\u003d\u003d\u003dreligion_transco(\"CODE\"), \"left\").withColumn(\"Actor2Religion1Name\", col(\"LABEL\")).drop(religion_transco.columns: _*)\nevents \u003d events.join(religion_transco, events(\"Actor2Religion2Code\")\u003d\u003d\u003dreligion_transco(\"CODE\"), \"left\").withColumn(\"Actor2Religion2Name\", col(\"LABEL\")).drop(religion_transco.columns: _*)\n\nevents \u003d events.join(type_transco, events(\"Actor1Type1Code\")\u003d\u003d\u003dtype_transco(\"CODE\"), \"left\").withColumn(\"Actor1Type1Name\", col(\"LABEL\")).drop(type_transco.columns: _*)\nevents \u003d events.join(type_transco, events(\"Actor1Type2Code\")\u003d\u003d\u003dtype_transco(\"CODE\"), \"left\").withColumn(\"Actor1Type2Name\", col(\"LABEL\")).drop(type_transco.columns: _*)\nevents \u003d events.join(type_transco, events(\"Actor1Type3Code\")\u003d\u003d\u003dtype_transco(\"CODE\"), \"left\").withColumn(\"Actor1Type3Name\", col(\"LABEL\")).drop(type_transco.columns: _*)\nevents \u003d events.join(type_transco, events(\"Actor2Type1Code\")\u003d\u003d\u003dtype_transco(\"CODE\"), \"left\").withColumn(\"Actor2Type1Name\", col(\"LABEL\")).drop(type_transco.columns: _*)\nevents \u003d events.join(type_transco, events(\"Actor2Type2Code\")\u003d\u003d\u003dtype_transco(\"CODE\"), \"left\").withColumn(\"Actor2Type2Name\", col(\"LABEL\")).drop(type_transco.columns: _*)\nevents \u003d events.join(type_transco, events(\"Actor2Type3Code\")\u003d\u003d\u003dtype_transco(\"CODE\"), \"left\").withColumn(\"Actor2Type3Name\", col(\"LABEL\")).drop(type_transco.columns: _*)\n\nevents \u003d events.join(quad_transco, events(\"QuadClass\")\u003d\u003d\u003dquad_transco(\"CODE\"), \"left\").withColumn(\"QuadClassType\", col(\"LABEL\")).drop(quad_transco.columns: _*)\n\nevents \u003d events.join(geoType_transco, events(\"Actor1Geo_Type\")\u003d\u003d\u003dgeoType_transco(\"CODE\"), \"left\").withColumn(\"Actor1Geo_Name\", col(\"LABEL\")).drop(geoType_transco.columns: _*)\nevents \u003d events.join(geoType_transco, events(\"Actor2Geo_Type\")\u003d\u003d\u003dgeoType_transco(\"CODE\"), \"left\").withColumn(\"Actor2Geo_Name\", col(\"LABEL\")).drop(geoType_transco.columns: _*)\nevents \u003d events.join(geoType_transco, events(\"ActionGeo_Type\")\u003d\u003d\u003dgeoType_transco(\"CODE\"), \"left\").withColumn(\"ActionGeo_Name\", col(\"LABEL\")).drop(geoType_transco.columns: _*)\n\nevents \u003d events.join(FIPS_transco, events(\"Actor1Geo_CountryCode\")\u003d\u003d\u003dFIPS_transco(\"CODE\"), \"left\").withColumn(\"Actor1Geo_CountryName\", col(\"LABEL\")).drop(FIPS_transco.columns: _*)\nevents \u003d events.join(FIPS_transco, events(\"Actor2Geo_CountryCode\")\u003d\u003d\u003dFIPS_transco(\"CODE\"), \"left\").withColumn(\"Actor2Geo_CountryName\", col(\"LABEL\")).drop(FIPS_transco.columns: _*)\nevents \u003d events.join(FIPS_transco, events(\"ActionGeo_CountryCode\")\u003d\u003d\u003dFIPS_transco(\"CODE\"), \"left\").withColumn(\"ActionGeo_CountryName\", col(\"LABEL\")).drop(FIPS_transco.columns: _*)",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.216",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "events: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 61 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 62 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 63 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 64 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 65 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 66 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 67 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 68 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 69 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 70 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 71 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 72 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 73 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 74 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 75 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 76 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 77 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 78 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 79 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 80 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 81 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 82 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 83 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 84 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 85 more fields]\nevents: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, SQLDATE: string ... 86 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760215_-1300748013",
      "id": "20190122-150742_902504965",
      "dateCreated": "2019-01-24 10:22:40.215",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "events.coalesce(1).write.mode(\"overwrite\").parquet(\"s3a://\" + bucket_name+ \"/DF/events/events01.parquet\")\n// mentions.coalesce(1).write.mode(\"overwrite\").parquet(\"s3a://\" + bucket_name+ \"/DF/mentions/mentions01.parquet\")",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.216",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1548321760216_-597457618",
      "id": "20190124-023616_1641377738",
      "dateCreated": "2019-01-24 10:22:40.216",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "mentions.coalesce(1).write.mode(\"overwrite\").parquet(\"s3a://\" + bucket_name+ \"/DF/mentions/mentions01.parquet\")",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.216",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1548321760216_854064669",
      "id": "20190124-031817_972776786",
      "dateCreated": "2019-01-24 10:22:40.216",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "mentions \u003d mentions.join(language_transco, mentions(\"MentionDocTranslationInfo\")\u003d\u003d\u003dlanguage_transco(\"CODE\"), \"left\").withColumn(\"Language\", col(\"LABEL\")).drop(language_transco.columns: _*)",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.217",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "mentions: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, EventTimeDate: string ... 14 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760216_1315215081",
      "id": "20190122-150850_614536411",
      "dateCreated": "2019-01-24 10:22:40.216",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "mentions.cache()",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.217",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "res220: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [GLOBALEVENTID: int, EventTimeDate: string ... 14 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760217_-103507313",
      "id": "20190123-213256_1203607766",
      "dateCreated": "2019-01-24 10:22:40.217",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "mentions.count()",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.217",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "res203: Long \u003d 73710722\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760217_-1967850388",
      "id": "20190122-150924_2001798567",
      "dateCreated": "2019-01-24 10:22:40.217",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Cassandra connector \nimport com.datastax.spark.connector._\nimport org.apache.spark.sql.cassandra._\nimport com.datastax.spark.connector.cql._\nval c \u003d CassandraConnector(sc.getConf)\nc.withSessionDo ( session \u003d\u003e session.execute(\"CREATE KEYSPACE queries WITH replication\u003d{\u0027class\u0027:\u0027SimpleStrategy\u0027, \u0027replication_factor\u0027:3}\"))",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.217",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import com.datastax.spark.connector._\nimport org.apache.spark.sql.cassandra._\nimport com.datastax.spark.connector.cql._\nc: com.datastax.spark.connector.cql.CassandraConnector \u003d com.datastax.spark.connector.cql.CassandraConnector@269760cf\nres223: com.datastax.driver.core.ResultSet \u003d ResultSet[ exhausted: true, Columns[]]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760217_1979004660",
      "id": "20190123-165432_276994982",
      "dateCreated": "2019-01-24 10:22:40.217",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "events.createOrReplaceTempView(\"events\")\n// mentions.createOrReplaceTempView(\"mentions\")",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.218",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1548321760217_887445600",
      "id": "20190123-172459_404346978",
      "dateCreated": "2019-01-24 10:22:40.217",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md # Query 1 processing",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.218",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eQuery 1 processing\u003c/h1\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760218_-1940919239",
      "id": "20190122-151000_420246314",
      "dateCreated": "2019-01-24 10:22:40.218",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\n\nval mentions_bis \u003d mentions.select($\"GLOBALEVENTID\".alias(\"eventid\"), $\"MentionIdentifier\".alias(\"documentid\"), $\"Language\".alias(\"language\")).distinct.where(\"language is not null\")\nval events_bis \u003d events.filter(month($\"SQLDate_date\")\u003d\u003d\u003d\"12\").select($\"GLOBALEVENTID\".alias(\"eventid\"), $\"SQLDATE\".alias(\"date\"), $\"ActionGeo_CountryName\".alias(\"country\")).where(\"country is not null\")\nval articles_and_events \u003d events_bis.join(mentions_bis, Seq(\"eventid\"), \"inner\")\n",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:23:20.858",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "mentions_bis: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [eventid: int, documentid: string ... 1 more field]\nevents_bis: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [eventid: int, date: string ... 1 more field]\narticles_and_events: org.apache.spark.sql.DataFrame \u003d [eventid: int, date: string ... 3 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760218_351182508",
      "id": "20190122-150931_1639174643",
      "dateCreated": "2019-01-24 10:22:40.218",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "articles_and_events.createCassandraTable(\n    \"queries\",\n    \"articles_and_events\", \n    partitionKeyColumns \u003d Some(Seq(\"date\",\"country\", \"language\")), \n    clusteringKeyColumns \u003d Some(Seq(\"eventid\")))\n",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.219",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "GLOBALEVENTID": "string",
                      "SQLDATE": "string",
                      "ActionGeo_CountryName": "string",
                      "MentionIdentifier": "string",
                      "Language": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1548321760218_-901607715",
      "id": "20190122-152421_1661109495",
      "dateCreated": "2019-01-24 10:22:40.218",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "articles_and_events.write.cassandraFormat(\"articles_and_events\", \"queries\").save()",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.219",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1548321760219_-329070433",
      "id": "20190123-192602_1233009422",
      "dateCreated": "2019-01-24 10:22:40.219",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md # Query 2 processing",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.219",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eQuery 2 processing\u003c/h1\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760219_-1065471781",
      "id": "20190122-150941_520019705",
      "dateCreated": "2019-01-24 10:22:40.219",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "var events_by_actor1 \u003d  events.select(\"Actor1Name\", \"SQLDATE\", \"GLOBALEVENTID\", \n\"Actor1CountryName\", \"Actor1KnownGroupName\" ,\"Actor1EthnicName\", \"Actor1Religion1Name\", \"Actor1Religion2Name\", \"Actor1Type1Name\", \"Actor1Type2Name\", \"Actor1Type3Name\", \n\"Actor2Name\", \"Actor2CountryName\", \"Actor2KnownGroupName\" ,\"Actor2EthnicName\", \"Actor2Religion1Name\", \"Actor2Religion2Name\", \"Actor2Type1Name\", \"Actor2Type2Name\", \"Actor2Type3Name\", \n\"Actor1Geo_Name\", \"Actor1Geo_FullName\", \"Actor1Geo_CountryName\", \"Actor1Geo_Lat\", \"Actor1Geo_Long\", \n\"Actor2Geo_Name\" , \"Actor2Geo_FullName\", \"Actor2Geo_CountryName\", \"Actor2Geo_Lat\", \"Actor2Geo_Long\",\n\"ActionGeo_Name\",  \"ActionGeo_FullName\",  \"ActionGeo_CountryName\", \"ActionGeo_Lat\", \"ActionGeo_Long\",\n\"EventCodeDesc\" , \"EventBaseCodeDesc\", \"EventRootCodeDesc\", \"QuadClassType\", \"GoldsteinScale\", \"NumMentions\", \"NumSources\", \"NumArticles\", \"AvgTone\", \"SOURCEURL\").\n                        withColumnRenamed(\"Actor1Name\", \"actor_name\").\n                        withColumnRenamed(\"SQLDATE\", \"event_date\").\n                        withColumnRenamed(\"GLOBALEVENTID\", \"event_id\").\n                        withColumnRenamed(\"Actor1CountryName\", \"actor_country\").\n                        withColumnRenamed(\"Actor1KnownGroupName\", \"actor_knowgroup\").\n                        withColumnRenamed(\"Actor1EthnicName\", \"actor_ethniccode\").\n                        withColumnRenamed(\"Actor1Religion1Name\", \"actor_religion1\").\n                        withColumnRenamed(\"Actor1Religion2Name\", \"actor_religion2\").\n                        withColumnRenamed(\"Actor1Type1Name\", \"actor_type1\").\n                        withColumnRenamed(\"Actor1Type2Name\", \"actor_type2\").\n                        withColumnRenamed(\"Actor1Type3Name\", \"actor_type3\").\n                        withColumnRenamed(\"Actor2Name\", \"co_actor_name\").\n                        withColumnRenamed(\"Actor2CountryName\", \"co_actor_country\").\n                        withColumnRenamed(\"Actor2KnownGroupName\", \"co_actor_knowgroup\").\n                        withColumnRenamed(\"Actor2EthnicName\", \"co_actor_ethniccode\").\n                        withColumnRenamed(\"Actor2Religion1Name\", \"co_actor_religion1\").\n                        withColumnRenamed(\"Actor2Religion2Name\", \"co_actor_religion2\").\n                        withColumnRenamed(\"Actor2Type1Name\", \"co_actor_type1\").\n                        withColumnRenamed(\"Actor2Type2Name\", \"co_actor_type2\").\n                        withColumnRenamed(\"Actor2Type3Name\", \"co_actor_type3\").\n                        withColumnRenamed(\"Actor1Geo_Name\", \"actor_event_type\").\n                        withColumnRenamed(\"Actor1Geo_FullName\", \"actor_event_localisation\").\n                        withColumnRenamed(\"Actor1Geo_CountryName\", \"actor_event_country\").\n                        withColumnRenamed(\"Actor1Geo_Lat\", \"actor_event_lat\").\n                        withColumnRenamed(\"Actor1Geo_Long\", \"actor_event_long\").\n                        withColumnRenamed(\"Actor2Geo_Name\", \"co_actor_event_type\").\n                        withColumnRenamed(\"Actor2Geo_FullName\", \"co_actor_event_localisation\").\n                        withColumnRenamed(\"Actor2Geo_CountryName\", \"co_actor_event_country\").\n                        withColumnRenamed(\"Actor2Geo_Lat\", \"co_actor_event_lat\").\n                        withColumnRenamed(\"Actor2Geo_Long\", \"co_actor_event_long\").\n                        withColumnRenamed(\"ActionGeo_Name\", \"action_type\").\n                        withColumnRenamed(\"ActionGeo_FullName\", \"action_localisation\").\n                        withColumnRenamed(\"ActionGeo_CountryName\", \"action_country\").\n                        withColumnRenamed(\"ActionGeo_Lat\", \"action_lat\").\n                        withColumnRenamed(\"ActionGeo_Long\", \"action_long\").\n                        withColumnRenamed(\"EventCodeDesc\", \"event_description\").\n                        withColumnRenamed(\"EventBaseCodeDesc\", \"event_base_description\").\n                        withColumnRenamed(\"EventRootCodeDesc\", \"event_root_description\").\n                        withColumnRenamed(\"QuadClassType\", \"event_quadclass\").\n                        withColumnRenamed(\"GoldsteinScale\", \"event_goldsteinscale\").\n                        withColumnRenamed(\"NumMentions\", \"event_nummentions\").\n                        withColumnRenamed(\"NumSources\", \"event_numsources\").\n                        withColumnRenamed(\"NumArticles\", \"event_articles\").\n                        withColumnRenamed(\"AvgTone\", \"event_avgtone\").\n                        withColumnRenamed(\"SOURCEURL\", \"event_url\").\n                        withColumn(\"action_performed_by_actor\", lit(true))\n",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.219",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "events_by_actor1: org.apache.spark.sql.DataFrame \u003d [actor_name: string, event_date: string ... 44 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760219_-2083211904",
      "id": "20190122-151018_285679246",
      "dateCreated": "2019-01-24 10:22:40.219",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "var events_by_actor2 \u003d  events.select(\"Actor1Name\", \"SQLDATE\", \"GLOBALEVENTID\", \n\"Actor1CountryName\", \"Actor1KnownGroupName\" ,\"Actor1EthnicName\", \"Actor1Religion1Name\", \"Actor1Religion2Name\", \"Actor1Type1Name\", \"Actor1Type2Name\", \"Actor1Type3Name\", \n\"Actor2Name\", \"Actor2CountryName\", \"Actor2KnownGroupName\" ,\"Actor2EthnicName\", \"Actor2Religion1Name\", \"Actor2Religion2Name\", \"Actor2Type1Name\", \"Actor2Type2Name\", \"Actor2Type3Name\", \n\"Actor1Geo_Name\", \"Actor1Geo_FullName\", \"Actor1Geo_CountryName\", \"Actor1Geo_Lat\", \"Actor1Geo_Long\", \n\"Actor2Geo_Name\" , \"Actor2Geo_FullName\", \"Actor2Geo_CountryName\", \"Actor2Geo_Lat\", \"Actor2Geo_Long\",\n\"ActionGeo_Name\",  \"ActionGeo_FullName\",  \"ActionGeo_CountryName\", \"ActionGeo_Lat\", \"ActionGeo_Long\",\n\"EventCodeDesc\" , \"EventBaseCodeDesc\", \"EventRootCodeDesc\", \"QuadClassType\", \"GoldsteinScale\", \"NumMentions\", \"NumSources\", \"NumArticles\", \"AvgTone\", \"SOURCEURL\").\n                        withColumnRenamed(\"Actor2Name\", \"actor_name\").\n                        withColumnRenamed(\"SQLDATE\", \"event_date\").\n                        withColumnRenamed(\"GLOBALEVENTID\", \"event_id\").\n                        withColumnRenamed(\"Actor2CountryName\", \"actor_country\").\n                        withColumnRenamed(\"Actor2KnownGroupName\", \"actor_knowgroup\").\n                        withColumnRenamed(\"Actor2EthnicName\", \"actor_ethniccode\").\n                        withColumnRenamed(\"Actor2Religion1Name\", \"actor_religion1\").\n                        withColumnRenamed(\"Actor2Religion2Name\", \"actor_religion2\").\n                        withColumnRenamed(\"Actor2Type1Name\", \"actor_type1\").\n                        withColumnRenamed(\"Actor2Type2Name\", \"actor_type2\").\n                        withColumnRenamed(\"Actor2Type3Name\", \"actor_type3\").\n                        withColumnRenamed(\"Actor1Name\", \"co_actor_name\").\n                        withColumnRenamed(\"Actor1CountryName\", \"co_actor_country\").\n                        withColumnRenamed(\"Actor1KnownGroupName\", \"co_actor_knowgroup\").\n                        withColumnRenamed(\"Actor1EthnicName\", \"co_actor_ethniccode\").\n                        withColumnRenamed(\"Actor1Religion1Name\", \"co_actor_religion1\").\n                        withColumnRenamed(\"Actor1Religion2Name\", \"co_actor_religion2\").\n                        withColumnRenamed(\"Actor1Type1Name\", \"co_actor_type1\").\n                        withColumnRenamed(\"Actor1Type2Name\", \"co_actor_type2\").\n                        withColumnRenamed(\"Actor1Type3Name\", \"co_actor_type3\").\n                        withColumnRenamed(\"Actor2Geo_Name\", \"actor_event_type\").\n                        withColumnRenamed(\"Actor2Geo_FullName\", \"actor_event_localisation\").\n                        withColumnRenamed(\"Actor2Geo_CountryName\", \"actor_event_country\").\n                        withColumnRenamed(\"Actor2Geo_Lat\", \"actor_event_lat\").\n                        withColumnRenamed(\"Actor2Geo_Long\", \"actor_event_long\").\n                        withColumnRenamed(\"Actor1Geo_Name\", \"co_actor_event_type\").\n                        withColumnRenamed(\"Actor1Geo_FullName\", \"co_actor_event_localisation\").\n                        withColumnRenamed(\"Actor1Geo_CountryName\", \"co_actor_event_country\").\n                        withColumnRenamed(\"Actor1Geo_Lat\", \"co_actor_event_lat\").\n                        withColumnRenamed(\"Actor1Geo_Long\", \"co_actor_event_long\").\n                        withColumnRenamed(\"ActionGeo_Name\", \"action_type\").\n                        withColumnRenamed(\"ActionGeo_FullName\", \"action_localisation\").\n                        withColumnRenamed(\"ActionGeo_CountryName\", \"action_country\").\n                        withColumnRenamed(\"ActionGeo_Lat\", \"action_lat\").\n                        withColumnRenamed(\"ActionGeo_Long\", \"action_long\").\n                        withColumnRenamed(\"EventCodeDesc\", \"event_description\").\n                        withColumnRenamed(\"EventBaseCodeDesc\", \"event_base_description\").\n                        withColumnRenamed(\"EventRootCodeDesc\", \"event_root_description\").\n                        withColumnRenamed(\"QuadClassType\", \"event_quadclass\").\n                        withColumnRenamed(\"GoldsteinScale\", \"event_goldsteinscale\").\n                        withColumnRenamed(\"NumMentions\", \"event_nummentions\").\n                        withColumnRenamed(\"NumSources\", \"event_numsources\").\n                        withColumnRenamed(\"NumArticles\", \"event_articles\").\n                        withColumnRenamed(\"AvgTone\", \"event_avgtone\").\n                        withColumnRenamed(\"SOURCEURL\", \"event_url\").\n                        withColumn(\"action_performed_by_actor\", lit(false))\n",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.220",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "events_by_actor2: org.apache.spark.sql.DataFrame \u003d [co_actor_name: string, event_date: string ... 44 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760219_479298450",
      "id": "20190123-170440_1976861644",
      "dateCreated": "2019-01-24 10:22:40.219",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "//  Filtetered on empty and null values and year is not 2018\nval events_by_actor1_filtered \u003d events_by_actor1.filter($\"actor_name\"  \u003d!\u003d \"\").\n                                            filter(\"actor_name is not null\").\n                                            filter($\"event_date\"  \u003d!\u003d \"\").\n                                            filter(\"event_date is not null\").\n                                            filter(\"event_id is not null\").\n                                            filter(year($\"event_date\")\u003d\u003d\u003d\"2018\").filter(month($\"event_date\")\u003elit(07))\n\n\nval events_by_actor2_filtered \u003d events_by_actor2.filter($\"actor_name\"  \u003d!\u003d \"\").\n                                            filter(\"actor_name is not null\").\n                                            filter($\"event_date\"  \u003d!\u003d \"\").\n                                            filter(\"event_date is not null\").\n                                            filter(\"event_id is not null\").\n                                            filter(year($\"event_date\")\u003d\u003d\u003d\"2018\").filter(month($\"event_date\")\u003elit(07))",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.220",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u003cconsole\u003e:8: error: Decimal integer literals may not have a leading zero. (Octal syntax is obsolete.)\n                                            filter(year($\"event_date\")\u003d\u003d\u003d\"2018\").filter(month($\"event_date\")\u003elit(07))\n                                                                                                                 ^\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760220_-1079104940",
      "id": "20190122-151648_379491646",
      "dateCreated": "2019-01-24 10:22:40.220",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.220",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1548321760220_1914278587",
      "id": "20190123-170841_1437930825",
      "dateCreated": "2019-01-24 10:22:40.220",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val events_by_actor \u003d events_by_actor1_filtered.union(events_by_actor1_filtered)",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.221",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u003cconsole\u003e:55: error: not found: value events_by_actor1_filtered\n       val events_by_actor \u003d events_by_actor1_filtered.union(events_by_actor1_filtered)\n                             ^\n\u003cconsole\u003e:55: error: not found: value events_by_actor1_filtered\n       val events_by_actor \u003d events_by_actor1_filtered.union(events_by_actor1_filtered)\n                                                             ^\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760220_1280271924",
      "id": "20190122-151949_1316270902",
      "dateCreated": "2019-01-24 10:22:40.221",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "events_by_actor.columns.foreach(println)",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.221",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "actor_name\nevent_date\nevent_id\nactor_country\nactor_knowgroup\nactor_ethniccode\nactor_religion1\nactor_religion2\nactor_type1\nactor_type2\nactor_type3\nco_actor_name\nco_actor_country\nco_actor_knowgroup\nco_actor_ethniccode\nco_actor_religion1\nco_actor_religion2\nco_actor_type1\nco_actor_type2\nco_actor_type3\nactor_event_type\nactor_event_localisation\nactor_event_country\nactor_event_lat\nactor_event_long\nco_actor_event_type\nco_actor_event_localisation\nco_actor_event_country\nco_actor_event_lat\nco_actor_event_long\naction_type\naction_localisation\naction_country\naction_lat\naction_long\nevent_description\nevent_base_description\nevent_root_description\nevent_quadclass\nevent_goldsteinscale\nevent_nummentions\nevent_numsources\nevent_articles\nevent_avgtone\nevent_url\naction_performed_by_actor\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760221_-582012893",
      "id": "20190123-170845_308115904",
      "dateCreated": "2019-01-24 10:22:40.221",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "events_by_actor.select(\"actor_name\").count()",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.221",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "org.apache.spark.SparkException: Job 76 cancelled part of cancelled job group zeppelin-2E1N33NQW-20190122-160604_250590039\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1803)\n  at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1738)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply$mcVI$sp(DAGScheduler.scala:851)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:851)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:851)\n  at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n  at org.apache.spark.scheduler.DAGScheduler.handleJobGroupCancelled(DAGScheduler.scala:851)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1993)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1973)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1962)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:682)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n  at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n  at org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:297)\n  at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2775)\n  at org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2774)\n  at org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3259)\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n  at org.apache.spark.sql.Dataset.withAction(Dataset.scala:3258)\n  at org.apache.spark.sql.Dataset.count(Dataset.scala:2774)\n  ... 70 elided\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760221_-2134479033",
      "id": "20190122-160604_250590039",
      "dateCreated": "2019-01-24 10:22:40.221",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "events_by_actor.createCassandraTable(\n    \"queries\",\n    \"events_by_actor\", \n    partitionKeyColumns \u003d Some(Seq(\"actor_name\")), \n    clusteringKeyColumns \u003d Some(Seq(\"event_date\", \"event_id\")))",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.222",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u003cconsole\u003e:57: error: not found: value events_by_actor\n       events_by_actor.createCassandraTable(\n       ^\n\u003cconsole\u003e:60: error: not found: value partitionKeyColumns\n           partitionKeyColumns \u003d Some(Seq(\"actor_name\")),\n           ^\n\u003cconsole\u003e:61: error: not found: value clusteringKeyColumns\n           clusteringKeyColumns \u003d Some(Seq(\"event_date\", \"event_id\")))\n           ^\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760221_1849048076",
      "id": "20190123-170903_840996572",
      "dateCreated": "2019-01-24 10:22:40.221",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "events_by_actor.write.cassandraFormat(\"events_by_actor\", \"queries\").save()",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.222",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1548321760222_156647186",
      "id": "20190123-175026_1976600764",
      "dateCreated": "2019-01-24 10:22:40.222",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md # Query 3 processing",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.222",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eQuery 3 processing\u003c/h1\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760222_-1676106699",
      "id": "20190122-151934_598773202",
      "dateCreated": "2019-01-24 10:22:40.222",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "var joined_df \u003d events.select($\"GLOBALEVENTID\", $\"SQLDate_date\", $\"Actor1Name\", $\"Actor2Name\",$\"Actor1Code\", $\"Actor2Code\", $\"ActionGeo_CountryName\").withColumn(\"SQLMonth\",month($\"SQLDate_date\")).join(mentions.select($\"GLOBALEVENTID\" , $\"MentionDocTone\", $\"Language\"), Seq(\"GLOBALEVENTID\"), \"inner\").drop(\"SQLDate_date\")\njoined_df \u003d joined_df.withColumn(\"Positive\", when( $\"MentionDocTone\"\u003e0, $\"MentionDocTone\").otherwise(0))\njoined_df \u003d joined_df.withColumn(\"Negative\", when( $\"MentionDocTone\"\u003c0,  $\"MentionDocTone\").otherwise(0)).drop(\"MentionDocTone\")\n\nvar df_actor1 \u003d joined_df.filter( \"Actor1Name !\u003d \u0027\u0027\").withColumn(\"ActorCode\", $\"Actor1Code\").withColumn(\"ActorName\", $\"Actor1Name\").drop(\"Actor1Name\").drop(\"Actor2Name\").drop(\"Actor1Code\").drop(\"Actor2Code\")\nvar df_actor2 \u003d joined_df.filter( \"Actor2Name !\u003d \u0027\u0027\").withColumn(\"ActorCode\", $\"Actor2Code\").withColumn(\"ActorName\", $\"Actor2Name\").drop(\"Actor1Name\").drop(\"Actor2Name\").drop(\"Actor1Code\").drop(\"Actor2Code\")\n\njoined_df \u003d df_actor1.union(df_actor2)\n\nvar df_query3 \u003d joined_df.groupBy(\"GLOBALEVENTID\",  \"SQLMonth\",  \"ActionGeo_CountryName\", \"Language\", \"ActorCode\", \"ActorName\").agg(sum(\"Positive\").as(\"positive\"),sum(\"Negative\").as(\"negative\")).select($\"GLOBALEVENTID\".alias(\"eventid\"), $\"SQLMonth\".alias(\"eventmonth\"), $\"ActionGeo_CountryName\".alias(\"countryname\"),$\"Language\".alias(\"language\"),$\"ActorCode\".alias(\"actorcode\"),$\"ActorName\".alias(\"actorname\"),$\"negative\",$\"positive\")\n\n//z.show(df_query3)",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.222",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "joined_df: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, Actor1Name: string ... 7 more fields]\njoined_df: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, Actor1Name: string ... 8 more fields]\njoined_df: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, Actor1Name: string ... 8 more fields]\ndf_actor1: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, ActionGeo_CountryName: string ... 6 more fields]\ndf_actor2: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, ActionGeo_CountryName: string ... 6 more fields]\njoined_df: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, ActionGeo_CountryName: string ... 6 more fields]\ndf_query3: org.apache.spark.sql.DataFrame \u003d [eventid: int, eventmonth: int ... 6 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760222_1138402063",
      "id": "20190122-152007_430034468",
      "dateCreated": "2019-01-24 10:22:40.222",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// df_query3.createCassandraTable(\n//   \"queries\",\n//   \"controversial_actors\",\n//   partitionKeyColumns \u003d Some(Seq(\"eventmonth\",\"countryname\",\"language\")),\n//   clusteringKeyColumns \u003d Some(Seq(\"eventid\")))\n\ndf_query3.write.cassandraFormat(\"controversial_actors\",\"queries\").save()",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.222",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "org.apache.spark.SparkException: Job 274 cancelled part of cancelled job group zeppelin-2E1N33NQW-20190123-212407_1533657810\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1803)\n  at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1738)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply$mcVI$sp(DAGScheduler.scala:851)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:851)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleJobGroupCancelled$1.apply(DAGScheduler.scala:851)\n  at scala.collection.mutable.HashSet.foreach(HashSet.scala:78)\n  at org.apache.spark.scheduler.DAGScheduler.handleJobGroupCancelled(DAGScheduler.scala:851)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1993)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1973)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1962)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:682)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087)\n  at com.datastax.spark.connector.RDDFunctions.saveToCassandra(RDDFunctions.scala:36)\n  at org.apache.spark.sql.cassandra.CassandraSourceRelation.insert(CassandraSourceRelation.scala:76)\n  at org.apache.spark.sql.cassandra.DefaultSource.createRelation(DefaultSource.scala:90)\n  at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:656)\n  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:656)\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n  at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:656)\n  at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)\n  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:267)\n  ... 70 elided\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760222_896989264",
      "id": "20190123-212407_1533657810",
      "dateCreated": "2019-01-24 10:22:40.222",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md # Query 4 processing",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.223",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eQuery 4 processing\u003c/h1\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760223_1146696052",
      "id": "20190122-152121_1251653524",
      "dateCreated": "2019-01-24 10:22:40.223",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val tableA \u003d events.filter(($\"Actor1Name\"  !\u003d\u003d \"\") || ($\"Actor1CountryName\"  !\u003d\u003d \"\") || ($\"Actor1KnownGroupName\"  !\u003d\u003d \"\")).select(\"SQLDATE\", \"Actor1Code\", \"Actor1CountryName\", \"Actor1KnownGroupName\", \"GLOBALEVENTID\")\n\nval tableM \u003d mentions.select(\"GLOBALEVENTID\", \"MentionDocTone\")\n\nval actor_final \u003d tableA.\n   join(tableM, \"GLOBALEVENTID\").\n   groupBy(\"GLOBALEVENTID\").\n   agg(max(col(\"SQLDATE\")),max(col(\"Actor1Code\")),max(col(\"Actor1CountryName\")),max(col(\"Actor1KnownGroupName\")),var_pop(col(\"MentionDocTone\")), count(col(\"GLOBALEVENTID\"))).\n   toDF(\"GLOBALEVENTID\",\"DATE\",\"ACTOR\",\"COUNTRY\",\"ORGANIZATION\",\"VARIANCE\",\"NB_ARTICLE\").\n   select(\"DATE\" as \"eventdate\",\"ACTOR\" as \"actor\",\"COUNTRY\" as \"country\",\"ORGANIZATION\" as \"organisation\",\"GLOBALEVENTID\" as \"globaleventid\", \"VARIANCE\" as \"variance\",\"NB_ARTICLE\" as \"nb_article\").\n   sort(asc(\"DATE\"), asc(\"ACTOR\"), asc(\"COUNTRY\"), asc(\"ORGANIZATION\"), asc(\"GLOBALEVENTID\"))",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.223",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "warning: there were three deprecation warnings; re-run with -deprecation for details\ntableA: org.apache.spark.sql.DataFrame \u003d [SQLDATE: string, Actor1Code: string ... 3 more fields]\ntableM: org.apache.spark.sql.DataFrame \u003d [GLOBALEVENTID: int, MentionDocTone: double]\nactor_final: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [DATE: string, ACTOR: string ... 5 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760223_39742525",
      "id": "20190122-152051_1099234903",
      "dateCreated": "2019-01-24 10:22:40.223",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val tableA \u003d events.filter(($\"Actor1Name\"  !\u003d\u003d \"\") || ($\"Actor1CountryName\"  !\u003d\u003d \"\") || ($\"Actor1KnownGroupName\"  !\u003d\u003d \"\")).\nselect($\"SQLDATE\".alias(\"date\"), $\"Actor1Code\".alias(\"actor1code\"), $\"Actor1CountryName\".alias(\"actor1country\"), $\"Actor1KnownGroupName\".alias(\"actor1knowngroup\"), $\"GLOBALEVENTID\".alias(\"globaleventid\"))\n\nval tableM \u003d mentions.select($\"GLOBALEVENTID\".alias(\"globaleventid\"), $\"MentionDocTone\".alias(\"mentiondoctone\"))\n\nval query4 \u003d tableA.\n   join(tableM, \"globaleventid\").\n   groupBy(\"globaleventid\").\n   agg(max(col(\"date\")),max(col(\"actor1code\")),max(col(\"actor1country\")),max(col(\"actor1knowngroup\")),var_pop(col(\"mentiondoctone\")), count(col(\"globaleventid\"))).\n   toDF(\"globaleventid\",\"eventdate\",\"actor\",\"country\",\"organization\",\"variance\",\"nb_article\").\n   select(\"eventdate\",\"actor\",\"country\",\"organization\",\"globaleventid\", \"variance\",\"nb_article\").\n   sort(asc(\"eventdate\"), asc(\"actor\"), asc(\"country\"), asc(\"organization\"), asc(\"globaleventid\"))",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.223",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "warning: there were three deprecation warnings; re-run with -deprecation for details\ntableA: org.apache.spark.sql.DataFrame \u003d [date: string, actor1code: string ... 3 more fields]\ntableM: org.apache.spark.sql.DataFrame \u003d [globaleventid: int, mentiondoctone: double]\nquery4: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [eventdate: string, actor: string ... 5 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760223_633521627",
      "id": "20190123-213037_492436437",
      "dateCreated": "2019-01-24 10:22:40.223",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// query4.createCassandraTable(\n//  \"queries\",\n//  \"divided_actors\",\n//  partitionKeyColumns \u003d Some(Seq(\"eventdate\")),\n//  clusteringKeyColumns \u003d Some(Seq(\"actor\", \"country\", \"organization\", \"globaleventid\")))\nquery4.write.cassandraFormat(\"divided_actors\", \"queries\").save()",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.223",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 171.0 failed 4 times, most recent failure: Lost task 0.3 in stage 171.0 (TID 3058, ip-172-31-51-129.ec2.internal, executor 288): ExecutorLostFailure (executor 288 exited caused by one of the running tasks) Reason: Container marked as failed: container_1548244662742_0004_01_001376 on host: ip-172-31-51-129.ec2.internal. Exit status: -100. Diagnostics: Container released on a *lost* node\nDriver stacktrace:\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1803)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1791)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1790)\n  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1790)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:871)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:871)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:871)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2024)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1973)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1962)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:682)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n  at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n  at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)\n  at org.apache.spark.RangePartitioner.\u003cinit\u003e(Partitioner.scala:171)\n  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:224)\n  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:91)\n  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:371)\n  at org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n  at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.DeserializeToObjectExec.doExecute(objects.scala:89)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n  at org.apache.spark.sql.Dataset.rdd$lzycompute(Dataset.scala:2980)\n  at org.apache.spark.sql.Dataset.rdd(Dataset.scala:2978)\n  at org.apache.spark.sql.cassandra.CassandraSourceRelation.insert(CassandraSourceRelation.scala:76)\n  at org.apache.spark.sql.cassandra.DefaultSource.createRelation(DefaultSource.scala:90)\n  at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:656)\n  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:656)\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n  at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:656)\n  at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)\n  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:267)\n  ... 70 elided\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760223_-1408466256",
      "id": "20190123-213527_1106041017",
      "dateCreated": "2019-01-24 10:22:40.223",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md # Query 5 processing : Number 1",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.224",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eQuery 5 processing : Number 1\u003c/h1\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760224_-2096076992",
      "id": "20190122-152135_1664805664",
      "dateCreated": "2019-01-24 10:22:40.224",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Events avg tone between actors\n\nval query_tone_actors_daily \u003d \"SELECT  Actor1Name as actor1name, Actor2Name as actor2name, SQLDATE as date, AVG(AvgTone) as daily_avg_tone FROM events Group by actor1name, actor2name, date Order by  date ASC \"\nval df_tone_actors_daily\u003d sqlContext.sql(query_tone_actors_daily).filter(($\"actor1name\" !\u003d\u003d \"\") \u0026\u0026 ($\"actor2name\" !\u003d\u003d \"\") )",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.224",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "query_tone_actors_daily: String \u003d \"SELECT  Actor1Name as actor1name, Actor2Name as actor2name, SQLDATE as date, AVG(AvgTone) as daily_avg_tone FROM events Group by actor1name, actor2name, date Order by  date ASC \"\nwarning: there were two deprecation warnings; re-run with -deprecation for details\ndf_tone_actors_daily: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [actor1name: string, actor2name: string ... 2 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760224_1031056729",
      "id": "20190122-152143_980315696",
      "dateCreated": "2019-01-24 10:22:40.224",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df_tone_actors_daily.createCassandraTable(\n    \"queries\",\n    \"tone_actors_daily\", \n    partitionKeyColumns \u003d Some(Seq(\"actor1name\",\"actor2name\")), \n    clusteringKeyColumns \u003d Some(Seq(\"date\")))",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.224",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "com.datastax.driver.core.exceptions.AlreadyExistsException: Table queries.tone_actors_daily already exists\n  at com.datastax.driver.core.exceptions.AlreadyExistsException.copy(AlreadyExistsException.java:111)\n  at com.datastax.driver.core.DriverThrowables.propagateCause(DriverThrowables.java:37)\n  at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:245)\n  at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:68)\n  at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:43)\n  at sun.reflect.GeneratedMethodAccessor350.invoke(Unknown Source)\n  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n  at java.lang.reflect.Method.invoke(Method.java:498)\n  at com.datastax.spark.connector.cql.SessionProxy.invoke(SessionProxy.scala:37)\n  at com.sun.proxy.$Proxy81.execute(Unknown Source)\n  at sun.reflect.GeneratedMethodAccessor350.invoke(Unknown Source)\n  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n  at java.lang.reflect.Method.invoke(Method.java:498)\n  at com.datastax.spark.connector.cql.SessionProxy.invoke(SessionProxy.scala:37)\n  at com.sun.proxy.$Proxy82.execute(Unknown Source)\n  at com.datastax.spark.connector.DataFrameFunctions$$anonfun$createCassandraTable$1.apply(DataFrameFunctions.scala:65)\n  at com.datastax.spark.connector.DataFrameFunctions$$anonfun$createCassandraTable$1.apply(DataFrameFunctions.scala:65)\n  at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$withSessionDo$1.apply(CassandraConnector.scala:112)\n  at com.datastax.spark.connector.cql.CassandraConnector$$anonfun$withSessionDo$1.apply(CassandraConnector.scala:111)\n  at com.datastax.spark.connector.cql.CassandraConnector.closeResourceAfterUse(CassandraConnector.scala:145)\n  at com.datastax.spark.connector.cql.CassandraConnector.withSessionDo(CassandraConnector.scala:111)\n  at com.datastax.spark.connector.DataFrameFunctions.createCassandraTable(DataFrameFunctions.scala:65)\n  ... 64 elided\nCaused by: com.datastax.driver.core.exceptions.AlreadyExistsException: Table queries.tone_actors_daily already exists\n  at com.datastax.driver.core.exceptions.AlreadyExistsException.copy(AlreadyExistsException.java:130)\n  at com.datastax.driver.core.Responses$Error.asException(Responses.java:140)\n  at com.datastax.driver.core.DefaultResultSetFuture.onSet(DefaultResultSetFuture.java:179)\n  at com.datastax.driver.core.RequestHandler.setFinalResult(RequestHandler.java:177)\n  at com.datastax.driver.core.RequestHandler.access$2500(RequestHandler.java:46)\n  at com.datastax.driver.core.RequestHandler$SpeculativeExecution.setFinalResult(RequestHandler.java:799)\n  at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:633)\n  at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1070)\n  at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:993)\n  at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)\n  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\n  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\n  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\n  at io.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:286)\n  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\n  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\n  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\n  at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)\n  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\n  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\n  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\n  at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:310)\n  at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:284)\n  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\n  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\n  at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)\n  at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359)\n  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)\n  at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)\n  at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935)\n  at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:801)\n  at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:404)\n  at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:304)\n  at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)\n  at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)\n  ... 1 more\nCaused by: com.datastax.driver.core.exceptions.AlreadyExistsException: Table queries.tone_actors_daily already exists\n  at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:85)\n  at com.datastax.driver.core.Responses$Error$1.decode(Responses.java:37)\n  at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:289)\n  at com.datastax.driver.core.Message$ProtocolDecoder.decode(Message.java:269)\n  at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:88)\n  ... 18 more\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760224_-604588843",
      "id": "20190123-165701_1477646573",
      "dateCreated": "2019-01-24 10:22:40.224",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df_tone_actors_daily.write.cassandraFormat(\"tone_actors_daily\", \"queries\").save()",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.224",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "org.apache.spark.SparkException: Job aborted due to stage failure: Task 24 in stage 71.0 failed 4 times, most recent failure: Lost task 24.3 in stage 71.0 (TID 490, ip-172-31-36-225.ec2.internal, executor 36): ExecutorLostFailure (executor 36 exited caused by one of the running tasks) Reason: Container marked as failed: container_1548298956086_0001_01_000046 on host: ip-172-31-36-225.ec2.internal. Exit status: 137. Diagnostics: Container killed on request. Exit code is 137\nContainer exited with a non-zero exit code 137\nKilled by external signal\n\nDriver stacktrace:\n  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1803)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1791)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1790)\n  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1790)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:871)\n  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:871)\n  at scala.Option.foreach(Option.scala:257)\n  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:871)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2024)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1973)\n  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1962)\n  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:682)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2034)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2055)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2074)\n  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2099)\n  at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\n  at org.apache.spark.rdd.RDD.collect(RDD.scala:944)\n  at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)\n  at org.apache.spark.RangePartitioner.\u003cinit\u003e(Partitioner.scala:171)\n  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:224)\n  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:91)\n  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)\n  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)\n  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)\n  at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:371)\n  at org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)\n  at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:605)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.DeserializeToObjectExec.doExecute(objects.scala:89)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n  at org.apache.spark.sql.Dataset.rdd$lzycompute(Dataset.scala:2980)\n  at org.apache.spark.sql.Dataset.rdd(Dataset.scala:2978)\n  at org.apache.spark.sql.cassandra.CassandraSourceRelation.insert(CassandraSourceRelation.scala:76)\n  at org.apache.spark.sql.cassandra.DefaultSource.createRelation(DefaultSource.scala:90)\n  at org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:45)\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:70)\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:68)\n  at org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:86)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)\n  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)\n  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:656)\n  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:656)\n  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)\n  at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:656)\n  at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)\n  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:267)\n  ... 64 elided\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760224_-276699997",
      "id": "20190123-165717_1429923805",
      "dateCreated": "2019-01-24 10:22:40.224",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md # Query 5 processing : Number 2",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.225",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eQuery 5 processing : Number 2\u003c/h1\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760225_1199651981",
      "id": "20190122-152159_906663149",
      "dateCreated": "2019-01-24 10:22:40.225",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val query_tone_country_daily \u003d \"SELECT  Actor1CountryName as actor1country , Actor2CountryName as actor2country, SQLDATE as date, AVG(AvgTone) as daily_avg_tone FROM events Group by actor1country, actor2country, date Order by  date ASC\"\nval df_tone_country_daily \u003d sqlContext.sql(query_tone_country_daily).filter(($\"actor1country\" !\u003d\u003d \"\") \u0026\u0026 ($\"actor2country\" !\u003d\u003d \"\"))",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.225",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "query_tone_country_daily: String \u003d SELECT  Actor1CountryName as actor1country , Actor2CountryName as actor2country, SQLDATE as date, AVG(AvgTone) as daily_avg_tone FROM events Group by actor1country, actor2country, date Order by  date ASC\nwarning: there were two deprecation warnings; re-run with -deprecation for details\ndf_tone_country_daily: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] \u003d [actor1country: string, actor2country: string ... 2 more fields]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760225_-507264196",
      "id": "20190122-152242_763239087",
      "dateCreated": "2019-01-24 10:22:40.225",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df_tone_country_daily.createCassandraTable(\n    \"queries\",\n    \"tone_country_daily\", \n    partitionKeyColumns \u003d Some(Seq(\"actor1country\",\"actor2country\")), \n    clusteringKeyColumns \u003d Some(Seq(\"date\")))\n",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.225",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1548321760225_511716999",
      "id": "20190123-165910_694834317",
      "dateCreated": "2019-01-24 10:22:40.225",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "df_tone_country_daily.write.cassandraFormat(\"tone_country_daily\", \"queries\").save()",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.226",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1548321760225_-370544443",
      "id": "20190123-165926_441667469",
      "dateCreated": "2019-01-24 10:22:40.225",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md # Load Cassandra",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.226",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9.0,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eLoad Cassandra\u003c/h1\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760226_-2117862897",
      "id": "20190122-163350_1916293865",
      "dateCreated": "2019-01-24 10:22:40.226",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "CREATE KEYSPACE test WITH replication \u003d {\u0027class\u0027: \u0027SimpleStrategy\u0027, \u0027replication_factor\u0027: 1 };",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.226",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u003cconsole\u003e:1: error: \u0027;\u0027 expected but symbol literal found.\nCREATE KEYSPACE test WITH replication \u003d {\u0027class\u0027: \u0027SimpleStrategy\u0027, \u0027replication_factor\u0027: 1 };\n                                               ^\n\u003cconsole\u003e:1: error: unclosed character literal\nCREATE KEYSPACE test WITH replication \u003d {\u0027class\u0027: \u0027SimpleStrategy\u0027, \u0027replication_factor\u0027: 1 };\n                                                                 ^\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1548321760226_1517318664",
      "id": "20190122-164524_1460151974",
      "dateCreated": "2019-01-24 10:22:40.226",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// events_by_actor.createCassandraTable(\n//     \"test\",\n//   \"events_by_actor\",\n//   partitionKeyColumns \u003d Some(Seq(\"actor_name\")),\n//   clusteringKeyColumns \u003d Some(Seq(\"event_date\", \"event_id\")))\n\nevents_by_actor.write.cassandraFormat(\"events_by_actor\", \"test\").save()",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.226",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": []
      },
      "apps": [],
      "jobName": "paragraph_1548321760226_-377915950",
      "id": "20190122-152307_1566105733",
      "dateCreated": "2019-01-24 10:22:40.226",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "import com.datastax.spark.connector._ //Imports basic rdd functions\nimport com.datastax.spark.connector.cql._ //(Optional) Imports java driver helper functions\nval c \u003d CassandraConnector(sc.getConf)\nc.withSessionDo ( session \u003d\u003e session.execute(\"CREATE KEYSPACE Tone_actors_daily WITH replication\u003d{\u0027class\u0027:\u0027SimpleStrategy\u0027, \u0027replication_factor\u0027:1}\"))\nc.withSessionDo ( session \u003d\u003e session.execute(\"CREATE TABLE Tone_actors_daily.test (k int PRIMARY KEY, v int)\"))",
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.227",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1548321760226_771168508",
      "id": "20190122-163114_1992445377",
      "dateCreated": "2019-01-24 10:22:40.226",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "anonymous",
      "dateUpdated": "2019-01-24 10:22:40.227",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1548321760227_586999935",
      "id": "20190122-163114_1403398939",
      "dateCreated": "2019-01-24 10:22:40.227",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "NoSQL_Q2",
  "id": "2E4K3X5UC",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "md:shared_process": [],
    "angular:shared_process": [],
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}